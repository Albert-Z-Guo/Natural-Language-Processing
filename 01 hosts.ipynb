{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 749 ms, sys: 122 ms, total: 871 ms\n",
      "Wall time: 871 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "year = 2013\n",
    "df = pd.read_json(path_or_buf='gg{0}.json'.format(year))\n",
    "# df = pd.read_json(path_or_buf='gg2015.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174643"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data if necessary\n",
    "data = df['text']\n",
    "sample_size = 200000\n",
    "if len(df) > sample_size:\n",
    "    data = data.sample(n=sample_size)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_freq_dict = {}\n",
    "\n",
    "def remove_retweet_prefix(line):\n",
    "    # find 'RT @abc: ' where abc's length is arbitrary\n",
    "    pattern = re.compile(r'\\bRT @([\\w\\'/]*)\\b: ') \n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        # store corresponding retweet without 'RT @' prefix\n",
    "        string = match.group()[4:]\n",
    "        if string in retweets_freq_dict:\n",
    "            retweets_freq_dict[string] += 1\n",
    "        else:\n",
    "            retweets_freq_dict[string] = 1\n",
    "    return re.sub(pattern, ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_freq_dict = {}\n",
    "\n",
    "def remove_hashtag(line):\n",
    "    pattern = re.compile(r'#([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in hashtag_freq_dict:\n",
    "                hashtag_freq_dict[match] += 1\n",
    "            else:\n",
    "                hashtag_freq_dict[match] = 1\n",
    "    return re.sub(pattern, ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_freq_dict = {}\n",
    "\n",
    "def remove_at(line):\n",
    "    pattern = re.compile(r'@([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in at_freq_dict:\n",
    "                at_freq_dict[match] += 1\n",
    "            else:\n",
    "                at_freq_dict[match] = 1\n",
    "    return re.sub(pattern, ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(line):\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b')\n",
    "    return re.sub(pattern, ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(line):\n",
    "    # replace everything to ' ' except whitespace, alphanumeric character, apostrophe, hashtag, @\n",
    "    return re.sub(r'[^\\w\\s\\'#@]', ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(text):\n",
    "    pattern = re.compile(r'\\'s\\b')\n",
    "    return re.sub(pattern, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded awards 2013-2015\n",
    "awards = ['cecil b. demille award', 'best motion picture - drama', \n",
    "          'best performance by an actress in a motion picture - drama', \n",
    "          'best performance by an actor in a motion picture - drama', \n",
    "          'best motion picture - comedy or musical', \n",
    "          'best performance by an actress in a motion picture - comedy or musical', \n",
    "          'best performance by an actor in a motion picture - comedy or musical', \n",
    "          'best animated feature film', \n",
    "          'best foreign language film', \n",
    "          'best performance by an actress in a supporting role in a motion picture', \n",
    "          'best performance by an actor in a supporting role in a motion picture', \n",
    "          'best director - motion picture', \n",
    "          'best screenplay - motion picture', \n",
    "          'best original score - motion picture', \n",
    "          'best original song - motion picture', \n",
    "          'best television series - drama', \n",
    "          'best performance by an actress in a television series - drama', \n",
    "          'best performance by an actor in a television series - drama', \n",
    "          'best television series - comedy or musical', \n",
    "          'best performance by an actress in a television series - comedy or musical', \n",
    "          'best performance by an actor in a television series - comedy or musical', \n",
    "          'best mini-series or motion picture made for television', \n",
    "          'best performance by an actress in a mini-series or motion picture made for television', \n",
    "          'best performance by an actor in a mini-series or motion picture made for television', \n",
    "          'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television', \n",
    "          'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set()\n",
    "awards_words = set()\n",
    "for award in awards:\n",
    "    awards_words |= set(cleanse(award).split())\n",
    "\n",
    "stop_words |= awards_words\n",
    "stop_words |= {'award'}\n",
    "stop_words |= {'awards'}\n",
    "stop_words |= {'tv'}\n",
    "stop_words |= {'movie'}\n",
    "stop_words |= {'movies'}\n",
    "stop_words |= {'win'}\n",
    "stop_words |= {'wins'}\n",
    "stop_words |= {'winner'}\n",
    "stop_words |= {'winners'}\n",
    "stop_words |= {'congrats'}\n",
    "stop_words |= {'congratulations'}\n",
    "stop_words |= {'golden'}\n",
    "stop_words |= {'globe'}\n",
    "stop_words |= {'globes'}\n",
    "stop_words |= {'rt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# reference for token attributes\n",
    "# https://spacy.io/api/token#attributes\n",
    "\n",
    "def identify_entities(text, stop_words):\n",
    "    tags = {}\n",
    "    for ent in nlp(text).ents:\n",
    "        entity = ent.text.strip()\n",
    "        if entity not in tags and len(entity) > 1:\n",
    "            # remove stopwords\n",
    "            entity_split = [w for w in entity.split() if w.lower() not in stop_words]            \n",
    "            if len(entity_split) != 0:\n",
    "                entity = ' '.join(entity_split)\n",
    "                if len(entity.split()) == 1 and entity.lower() == 'the':\n",
    "                    pass\n",
    "                else:\n",
    "                    tags[entity]=[ent.label_]\n",
    "    return tags\n",
    "\n",
    "# performance may be compared with nltk.tag.stanford.StanfordTagger if we have time\n",
    "# http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174643\n",
      "125587\n",
      "CPU times: user 3.39 s, sys: 11.8 ms, total: 3.4 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate cleansed_data beforehand\n",
    "\n",
    "cleansed_data = []\n",
    "for tweet in data:\n",
    "    line = remove_retweet_prefix(tweet)\n",
    "    line = remove_hashtag(line)\n",
    "    line = remove_at(line)\n",
    "    line = remove_url(line)\n",
    "    line = cleanse(line)\n",
    "    cleansed_data.append(line)\n",
    "    \n",
    "# remove redundancies after processing retweets\n",
    "print(len(cleansed_data))\n",
    "cleansed_data = list(set(cleansed_data))\n",
    "print(len(cleansed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Love Tina Fays comment bout taylor swift   ',\n",
       " ' I bet the Life of Pi wins 3 14 awards tonight   ',\n",
       " 'Tremendo  ',\n",
       " ' Best TV movie or miniseries actor goes to   for         ',\n",
       " 'Catherine  cari√±o  para cantar una frase mejor no hacer nada   ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_host(cleansed_data, awards, verbose=False):\n",
    "    pattern = re.compile(r'\\bhost')\n",
    "    entity_freq_dict = {}\n",
    "    \n",
    "    num = 0\n",
    "    max_entity_len = 0\n",
    "    max_entity = None\n",
    "    for line in cleansed_data:\n",
    "        match = re.search(pattern, line.lower())\n",
    "        if match:\n",
    "            tags = identify_entities(line, stop_words)\n",
    "\n",
    "            if verbose:\n",
    "                # print the first 10 occurrences\n",
    "                if num < 10:\n",
    "                    print(tweet)\n",
    "                    print(line)\n",
    "                    print(tags)\n",
    "                    print()\n",
    "\n",
    "            for entity in tags.keys():\n",
    "                # identify the entity with maximum length\n",
    "                entity_len = len(entity)\n",
    "                if entity_len > max_entity_len:\n",
    "                    max_entity_len = entity_len\n",
    "                    max_entity = entity\n",
    "                \n",
    "                if entity not in entity_freq_dict:\n",
    "                    entity_freq_dict[entity] = 1 # tried adding more weights to 'PERSON' tags but results are not good\n",
    "                else:\n",
    "                    entity_freq_dict[entity] += 1\n",
    "            num += 1           \n",
    "    print('num of matches:', num)\n",
    "    print('max_entity_len:', max_entity_len)\n",
    "    print('max_entity:', max_entity)\n",
    "    return entity_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "Tina and Amy hosting the   was just genius    \n",
      "{'Tina': ['GPE'], 'Amy': ['PERSON']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "It's kind of uppsetting that Tina Fey and Amy Poehler are hosting the Golden Globes \n",
      "{'Amy Poehler': ['PERSON']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "I can't wait to do my all pirate hostage rescue film  YARGO   \n",
      "{}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "AGREE   Great     amusingly hosted  memorable speeches  mostly correct winners  Thoroughly enjoyed it \n",
      "{'Thoroughly': ['NORP']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "Amy and Tina fey ate hosting    Just started and it's already the funniest golden globes I've ever watched \n",
      "{'Amy': ['PERSON'], 'Tina': ['GPE']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "Umm  NO   Just thinking ahead  but like should Will Ferrell and Kristen Wiig host the   together next year  \n",
      "{'Will Ferrell': ['PERSON'], 'Kristen Wiig': ['PERSON'], 'next year': ['DATE']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "Can we sign Wiig and Ferrell up as next year's hosts   \n",
      "{'Wiig': ['PERSON'], 'Ferrell': ['PERSON'], \"next year's\": ['DATE']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "  Tina Fey  amp  Amy Poehler hosting the globes  Just give me the list of winners  they should do the entire 3 hours show   lt 3 Love \n",
      "{'Tina Fey': ['ORG'], 'Amy Poehler': ['PERSON'], 'the entire 3 hours': ['TIME'], '3 Love': ['WORK_OF_ART']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      " Tina Fey and Amy Poehler hosting the Golden Globes  best idea of 2013 yet\n",
      "{'Tina Fey': ['ORG'], 'Amy Poehler': ['PERSON'], '2013': ['DATE']}\n",
      "\n",
      "Says @BenAffleck: \"I also didn't get the Acting Nomination...no one's saying I got snubbed there!\" #pressroom #GoldenGlobes\n",
      "OK  enough Golden Globes chatter from me  Off to host karaoke at Toby's tonight  Pretty sure it'll be more entertaining than half this show \n",
      "{'Toby': ['ORG'], 'tonight': ['TIME'], 'Pretty': ['PERSON'], 'half': ['CARDINAL']}\n",
      "\n",
      "num of matches: 1683\n",
      "max_entity_len: 29\n",
      "max_entity: Amy Poehler on Hosting People\n",
      "CPU times: user 1min, sys: 7.56 s, total: 1min 7s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# note that for 2015 tweets, it takes more than 4min to run\n",
    "# processing time may be long for large data\n",
    "# consider picking the longest 150000 tweets\n",
    "\n",
    "entity_freq_dict = find_host(cleansed_data, awards, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('goldenglobes: ', 6918),\n",
       " ('eonline: ', 5782),\n",
       " ('PerezHilton: ', 4602),\n",
       " ('TheEllenShow: ', 3392),\n",
       " ('EmWatson: ', 2294),\n",
       " ('VanityFair: ', 1640),\n",
       " ('nbcsnl: ', 1486),\n",
       " ('CNNshowbiz: ', 1398),\n",
       " ('CiudadBizarra: ', 1020),\n",
       " ('BuzzFeed: ', 982),\n",
       " ('EW: ', 970),\n",
       " ('nbc: ', 930),\n",
       " ('vulture: ', 892),\n",
       " ('piersmorgan: ', 882),\n",
       " ('MARLONLWAYANS: ', 768),\n",
       " ('HuffingtonPost: ', 738),\n",
       " ('buckhollywood: ', 706),\n",
       " ('MarilynMonroeES: ', 668),\n",
       " ('TVGuide: ', 638),\n",
       " ('THR: ', 630),\n",
       " ('DavidSpade: ', 624),\n",
       " ('MTVNews: ', 614),\n",
       " ('PimpBillClinton: ', 562),\n",
       " ('cinema21: ', 562),\n",
       " ('washingtonpost: ', 550),\n",
       " ('ninagarcia: ', 516),\n",
       " ('Cosmopolitan: ', 478),\n",
       " ('peopleenespanol: ', 438),\n",
       " ('RichardCrouse: ', 434),\n",
       " ('peoplemag: ', 426),\n",
       " ('prodigalsam: ', 424),\n",
       " ('kumailn: ', 422),\n",
       " ('DannyZuker: ', 414),\n",
       " ('jianghomeshi: ', 402),\n",
       " ('HuffPostWomen: ', 400),\n",
       " ('DamienFahey: ', 400),\n",
       " ('girlsHBO: ', 396),\n",
       " ('MHarrisPerry: ', 388),\n",
       " ('DougBenson: ', 384),\n",
       " ('rogergzz: ', 382),\n",
       " ('InStyle: ', 382),\n",
       " ('EonlineLatino: ', 376),\n",
       " ('TVWithoutPity: ', 374),\n",
       " ('glamourmag: ', 362),\n",
       " ('CinePREMIERE: ', 348),\n",
       " ('unfoRETTAble: ', 346),\n",
       " ('HuffPostEnt: ', 334),\n",
       " ('msleamichele: ', 328),\n",
       " ('SofiaVergara: ', 320),\n",
       " ('heidiklum: ', 316)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top retweets (each as an entity)\n",
    "sorted(retweets_freq_dict.items(), key=lambda pair: pair[1], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GoldenGlobes', 220270),\n",
       " ('goldenglobes', 66226),\n",
       " ('Argo', 1684),\n",
       " ('GetGlue', 1538),\n",
       " ('Homeland', 1392),\n",
       " ('redcarpet', 1350),\n",
       " ('GoldenGlobe', 1142),\n",
       " ('Goldenglobes', 1120),\n",
       " ('JodieFoster', 972),\n",
       " ('Girls', 902),\n",
       " ('killingit', 894),\n",
       " ('GOLDENGLOBES', 840),\n",
       " ('AlfombraRojaE', 770),\n",
       " ('Skyfall', 720),\n",
       " ('GlobosdeOro', 704),\n",
       " ('RedCarpet', 696),\n",
       " ('Lincoln', 696),\n",
       " ('LesMis', 692),\n",
       " ('GIRLS', 664),\n",
       " ('Adele', 578),\n",
       " ('LesMiserables', 564),\n",
       " ('JenniferLawrence', 516),\n",
       " ('GG2013', 508),\n",
       " ('homeland', 502),\n",
       " ('GoldenGlobes2013', 498),\n",
       " ('TinaFey', 452),\n",
       " ('ERedCarpet', 448),\n",
       " ('AmyPoehler', 418),\n",
       " ('eredcarpet', 414),\n",
       " ('jodiefoster', 408),\n",
       " ('DowntonAbbey', 386),\n",
       " ('AnneHathaway', 382),\n",
       " ('girls', 376),\n",
       " ('DjangoUnchained', 368),\n",
       " ('Oscars', 352),\n",
       " ('LoveThoseLadies', 326),\n",
       " ('Django', 316),\n",
       " ('BenAffleck', 308),\n",
       " ('Globes', 298),\n",
       " ('GameChange', 292),\n",
       " ('LOVEHER', 292),\n",
       " ('goldenGlobes', 286),\n",
       " ('fb', 286),\n",
       " ('BillClinton', 284),\n",
       " ('fashion', 276),\n",
       " ('Oscar', 276),\n",
       " ('skyfall', 274),\n",
       " ('watchyourbackAdele', 266),\n",
       " ('adele', 260),\n",
       " ('argo', 256)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top hashtags\n",
    "sorted(hashtag_freq_dict.items(), key=lambda pair: pair[1], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('goldenglobes', 6300),\n",
       " ('OfficialAdele', 2244),\n",
       " ('lenadunham', 1960),\n",
       " ('GoldenGlobes', 1726),\n",
       " ('BenAffleck', 1052),\n",
       " ('RealHughJackman', 772),\n",
       " ('PerezHilton', 722),\n",
       " ('SHO_Homeland', 714),\n",
       " ('girlsHBO', 704),\n",
       " ('SofiaVergara', 606),\n",
       " ('eonline', 580),\n",
       " ('taylorswift13', 540),\n",
       " ('TNTLA', 510),\n",
       " ('JLo', 470),\n",
       " ('PaulEpworth', 446),\n",
       " ('GirlsHBO', 364),\n",
       " ('msleamichele', 334),\n",
       " ('SelenaGomez', 328),\n",
       " ('VanessuHudgens', 326),\n",
       " ('LenaDunham', 312),\n",
       " ('steph_hart', 312),\n",
       " ('RyanGosling', 274),\n",
       " ('kerrywashington', 250),\n",
       " ('PixarBrave', 240),\n",
       " ('LesMiserables', 226),\n",
       " ('nbc', 224),\n",
       " ('Chanel', 224),\n",
       " ('NathanFillion', 210),\n",
       " ('KevalBaxi', 194),\n",
       " ('Burberry', 172),\n",
       " ('Lewis_Damian', 172),\n",
       " ('jessicaalba', 168),\n",
       " ('CHANEL', 166),\n",
       " ('tomandlorenzo', 156),\n",
       " ('nbcsnl', 154),\n",
       " ('iamdoncheadle', 152),\n",
       " ('piersmorgan', 138),\n",
       " ('CiudadBizarra', 134),\n",
       " ('CNNshowbiz', 128),\n",
       " ('BuzzFeed', 128),\n",
       " ('LeoDiCaprio', 124),\n",
       " ('EvaLongoria', 122),\n",
       " ('azizansari', 120),\n",
       " ('gabrielledoug', 120),\n",
       " ('Sarah_Hyland', 120),\n",
       " (\"lenadunham's\", 116),\n",
       " ('WorldMcQueen', 110),\n",
       " ('EW', 110),\n",
       " ('Solvej_Schou', 110),\n",
       " ('officialadele', 108)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top @\n",
    "sorted(at_freq_dict.items(), key=lambda pair: pair[1], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amy Poehler', 420),\n",
       " ('Amy', 318),\n",
       " ('Tina', 287),\n",
       " ('Tina Fey', 199),\n",
       " ('Will Ferrell', 151),\n",
       " ('next year', 137),\n",
       " ('Kristen Wiig', 121),\n",
       " ('two', 46),\n",
       " ('2014', 41),\n",
       " ('tonight', 40),\n",
       " (\"next year's\", 32),\n",
       " ('SNL', 28),\n",
       " ('every year', 25),\n",
       " ('Oscars next year', 22),\n",
       " ('Amy Pohler', 20),\n",
       " ('Opening Monologue', 20),\n",
       " ('Poehler', 19),\n",
       " ('this year', 19),\n",
       " ('Hollywood', 18),\n",
       " ('Hosts Tina', 17),\n",
       " ('Amy Poelher', 17),\n",
       " ('Love', 15),\n",
       " ('Wiig', 14),\n",
       " ('Oscars', 14),\n",
       " ('2013', 13),\n",
       " ('Hosts', 13),\n",
       " ('Ferrell', 12),\n",
       " ('first', 12),\n",
       " ('Cohen', 12),\n",
       " ('Kristin Wiig', 11),\n",
       " ('Ricky Gervais', 11),\n",
       " (\"Amy Poehler's\", 11),\n",
       " ('next years', 11),\n",
       " ('Kristen Wiig and', 10),\n",
       " ('Paul Rudd', 10),\n",
       " ('Can Tina Fey', 10),\n",
       " ('Thoroughly', 9),\n",
       " ('Kristen Wig', 8),\n",
       " ('one', 8),\n",
       " ('Host', 8),\n",
       " ('Great', 8),\n",
       " ('Can', 8),\n",
       " ('year', 7),\n",
       " ('Jodie Foster', 7),\n",
       " ('Adele', 7),\n",
       " ('Jennifer Lawrence', 7),\n",
       " ('Will Ferrel', 7),\n",
       " ('Kristin', 7),\n",
       " ('Amy Poehler on Hosting', 6),\n",
       " ('Bill Clinton', 6),\n",
       " ('Will Farrell', 6),\n",
       " ('70th', 6),\n",
       " ('Sacha', 6),\n",
       " ('Oscar', 6),\n",
       " ('Jay Leno', 6),\n",
       " ('LOL', 6),\n",
       " ('Will', 6),\n",
       " ('Iran', 6),\n",
       " ('Hilarious', 5),\n",
       " (\"Next year's\", 5),\n",
       " ('AMY', 5),\n",
       " ('GG', 5),\n",
       " ('Anne Hathaway', 5),\n",
       " ('Fey', 5),\n",
       " ('Taylor Swift', 5),\n",
       " ('James Franco', 5),\n",
       " ('James Cameron', 5),\n",
       " ('Jimmy Fallon', 5),\n",
       " ('Kristen', 5),\n",
       " ('Can Tina', 5),\n",
       " ('NBC', 5),\n",
       " ('Sasha', 5),\n",
       " ('Tina Amy', 4),\n",
       " ('Hosted', 4),\n",
       " ('The Japanese Cojo', 4),\n",
       " ('So', 4),\n",
       " ('Lol', 4),\n",
       " ('Glenn Close', 4),\n",
       " ('hosts', 4),\n",
       " ('Robert Downey Jr', 4),\n",
       " ('Please', 4),\n",
       " ('Tina Fay', 4),\n",
       " ('Tonight', 4),\n",
       " ('Quentin Tarantino', 4),\n",
       " ('HFPA', 4),\n",
       " ('Amy Poeler', 4),\n",
       " ('Seth', 3),\n",
       " ('night', 3),\n",
       " ('Open Post', 3),\n",
       " (\"Pressure's\", 3),\n",
       " ('this every year', 3),\n",
       " ('Kristen Wigg', 3),\n",
       " ('Academy', 3),\n",
       " ('DO', 3),\n",
       " ('HOSTS', 3),\n",
       " ('Super', 3),\n",
       " ('Hollywood Press Association', 3),\n",
       " ('Run the World', 3),\n",
       " ('Funny', 3),\n",
       " ('Seth MacFarlane', 3)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100 = sorted(entity_freq_dict.items(), key=lambda pair: pair[1], reverse=True)[:100]\n",
    "top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "43\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "# pip3 install python-Levenshtein for 4-10x speedup\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# test\n",
    "print(fuzz.ratio('Tina Fey', 'Tina'))\n",
    "print(fuzz.ratio('Amy Poehler', 'Amy'))\n",
    "print(fuzz.ratio('Golden Globes', 'golden globes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# remove golden globes from names\n",
    "import pprint\n",
    "names = [pair[0] for pair in top_100]\n",
    "golden_globes = [name for name in names if fuzz.ratio(name.lower(), 'golden globes') > 70]\n",
    "pprint.pprint(golden_globes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also consider dropping all lower cases examples or examples that contain digit(s), which are not names\n",
    "def filter_names(pair_list):\n",
    "    filtered_results = []\n",
    "    for pair in pair_list:\n",
    "        string = ''.join(pair[0].split())\n",
    "        if not all(char.islower() for char in string) and not any(char.isdigit() for char in string):\n",
    "            filtered_results.append(pair)\n",
    "        else:\n",
    "            if pair[0] in entity_freq_dict:\n",
    "                del entity_freq_dict[pair[0]]\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amy Poehler', 420),\n",
       " ('Amy', 318),\n",
       " ('Tina', 287),\n",
       " ('Tina Fey', 199),\n",
       " ('Will Ferrell', 151),\n",
       " ('Kristen Wiig', 121),\n",
       " (\"next year's\", 32),\n",
       " ('SNL', 28),\n",
       " ('Oscars next year', 22),\n",
       " ('Amy Pohler', 20),\n",
       " ('Opening Monologue', 20),\n",
       " ('Poehler', 19),\n",
       " ('Hollywood', 18),\n",
       " ('Hosts Tina', 17)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in golden_globes:\n",
    "    if name in entity_freq_dict:\n",
    "        del entity_freq_dict[name]\n",
    "top_results = sorted(entity_freq_dict.items(), key=lambda pair: pair[1], reverse=True)[:20]\n",
    "top_results = filter_names(top_results)\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amy Poehler', 'Amy', 'Amy Pohler', 'Poehler']\n",
      "['Amy', 'Amy Poehler', 'Amy Pohler']\n",
      "['Tina', 'Tina Fey', 'Hosts Tina']\n",
      "['Tina Fey', 'Tina']\n",
      "['Will Ferrell']\n",
      "['Kristen Wiig']\n",
      "[\"next year's\"]\n",
      "['SNL']\n",
      "['Oscars next year']\n",
      "['Amy Pohler', 'Amy Poehler', 'Amy']\n",
      "['Opening Monologue']\n",
      "['Poehler', 'Amy Poehler']\n",
      "['Hollywood']\n",
      "['Hosts Tina', 'Tina']\n",
      "\n",
      "names clusters to merge:\n",
      "[['Tina', 'Tina Fey'],\n",
      " ['Hosts Tina', 'Tina'],\n",
      " ['Amy Poehler', 'Poehler'],\n",
      " ['Amy', 'Amy Poehler', 'Amy Pohler'],\n",
      " ['Hosts Tina', 'Tina', 'Tina Fey'],\n",
      " ['Amy', 'Amy Poehler', 'Amy Pohler', 'Poehler']]\n"
     ]
    }
   ],
   "source": [
    "names = [pair[0] for pair in top_results]\n",
    "names_clusters = []\n",
    "\n",
    "for name in names:\n",
    "    # each name starts as a cluster\n",
    "    cluster = [name]\n",
    "    names_to_reduce = names[:]\n",
    "    names_to_reduce.remove(name)\n",
    "    \n",
    "    # one vs. all comparisons\n",
    "    for i in names_to_reduce:\n",
    "        ratio = fuzz.ratio(name.lower(), i.lower())\n",
    "        # if similarity is larger than 75 or one name is contained in the other name\n",
    "        if ratio > 75 or re.search(name, i, flags=re.IGNORECASE) or re.search(i, name, flags=re.IGNORECASE):\n",
    "            cluster.append(i)\n",
    "    \n",
    "    # if multiple names are identified in one cluster\n",
    "    if len(cluster) > 1:\n",
    "        names_clusters.append(cluster)\n",
    "    \n",
    "    print(cluster)\n",
    "\n",
    "# find names clusters that should merge\n",
    "# ['Amy Poehler', 'Amy', 'Amy Poelher']\n",
    "# ['Tina', 'Tina Fey']\n",
    "\n",
    "# sort clusters\n",
    "names_clusters.sort()\n",
    "# sort within each cluster\n",
    "names_clusters = ['|'.join(sorted(cluster)) for cluster in names_clusters]\n",
    "# remove overlaps\n",
    "names_clusters_reduced = [line.split('|') for line in list(set(names_clusters))]\n",
    "# sort by length from shortest to longest (merge from the shortest)\n",
    "names_clusters_reduced.sort(key=len)\n",
    "print('\\nnames clusters to merge:')\n",
    "pprint.pprint(names_clusters_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# weighted frequency of an entity is defined by its frequency multiplied by its string length\n",
    "def weighted_freq(element):\n",
    "    return entity_freq_dict[element] * len(element)\n",
    "\n",
    "e = entity_freq_dict.copy()\n",
    "for cluster in names_clusters_reduced:\n",
    "    # select the entity name with highest weighted frequency\n",
    "    selected_entity_name = max(cluster, key=weighted_freq)\n",
    "    cluster.remove(selected_entity_name)\n",
    "    # for names to be merged to the selected entity name\n",
    "    for name in cluster:\n",
    "        # if not deleted in previous cases, cumulate frequencies to the selected entity\n",
    "        if name in e and selected_entity_name in e:\n",
    "            e[selected_entity_name] += e[name]\n",
    "            # reward merging\n",
    "#             e[selected_entity_name] += round(e[selected_entity_name]*1/(names.index(selected_entity_name)+1-0.8) / e[name])\n",
    "#             e[selected_entity_name] += round(e[selected_entity_name]*1/(names.index(selected_entity_name)+1-0.8) * (1 + 1/e[name]))\n",
    "            del e[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amy Poehler', 777),\n",
       " ('Tina Fey', 503),\n",
       " ('Will Ferrell', 151),\n",
       " ('Kristen Wiig', 121),\n",
       " (\"next year's\", 32),\n",
       " ('SNL', 28),\n",
       " ('Oscars next year', 22),\n",
       " ('Opening Monologue', 20),\n",
       " ('Hollywood', 18),\n",
       " ('Amy Poelher', 17)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = sorted(e.items(), key=lambda pair: pair[1], reverse=True)[:10]\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Host\": [\"Amy Poehler\", \"Amy\"]}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# top 2 inferences for hosts\n",
    "best_host_prediction = [name[0] for name in top_10][:2]\n",
    "json.dumps({'Host': best_host_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
