{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290620657987887104</td>\n",
       "      <td>JLo's dress! #eredcarpet #GoldenGlobes</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "      <td>{'screen_name': 'Dozaaa_xo', 'id': 557374298}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290620657887219713</td>\n",
       "      <td>What's making Sofia Vergara's boobs stay like ...</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "      <td>{'screen_name': 'theAmberShow', 'id': 14648726}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290620657828524032</td>\n",
       "      <td>RT @FabSugar: Kerry Washington is EVERYTHING. ...</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "      <td>{'screen_name': 'SweetyPW', 'id': 35498686}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  290620657987887104             JLo's dress! #eredcarpet #GoldenGlobes   \n",
       "1  290620657887219713  What's making Sofia Vergara's boobs stay like ...   \n",
       "2  290620657828524032  RT @FabSugar: Kerry Washington is EVERYTHING. ...   \n",
       "\n",
       "         timestamp_ms                                             user  \n",
       "0 2013-01-14 00:45:38    {'screen_name': 'Dozaaa_xo', 'id': 557374298}  \n",
       "1 2013-01-14 00:45:38  {'screen_name': 'theAmberShow', 'id': 14648726}  \n",
       "2 2013-01-14 00:45:38      {'screen_name': 'SweetyPW', 'id': 35498686}  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(path_or_buf='gg2013.json')\n",
    "# df = pd.read_json(path_or_buf='gg2015.json')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               JLo's dress! #eredcarpet #GoldenGlobes\n",
       "1    What's making Sofia Vergara's boobs stay like ...\n",
       "2    RT @FabSugar: Kerry Washington is EVERYTHING. ...\n",
       "3       Anne Hathaway has got me living. #GoldenGlobes\n",
       "4    Jennifer Lopez's lace dress? Thoughts? #Golden...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df['text']\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174643"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174643"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data if necessary\n",
    "sample_size = 200000\n",
    "if len(df) > sample_size:\n",
    "    data = data.sample(n=sample_size)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_freq_dict = {}\n",
    "\n",
    "def remove_retweet_prefix(line):\n",
    "    # find 'RT @abc: ' where abc's length is arbitrary\n",
    "    pattern = re.compile(r'\\bRT @([\\w\\'/]*)\\b: ') \n",
    "   \n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        # store corresponding retweet without 'RT @' prefix\n",
    "        string = match.group()[4:]\n",
    "        if string in retweets_freq_dict:\n",
    "            retweets_freq_dict[string] += 1\n",
    "        else:\n",
    "            retweets_freq_dict[string] = 1\n",
    "        \n",
    "    return re.sub(pattern, ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_freq_dict = {}\n",
    "\n",
    "def remove_hashtag(line):\n",
    "    pattern = re.compile(r'#([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in hashtag_freq_dict:\n",
    "                hashtag_freq_dict[match] += 1\n",
    "            else:\n",
    "                hashtag_freq_dict[match] = 1\n",
    "        \n",
    "    line = re.sub(pattern, ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_freq_dict = {}\n",
    "\n",
    "def remove_at(line):\n",
    "    pattern = re.compile(r'@([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in at_freq_dict:\n",
    "                at_freq_dict[match] += 1\n",
    "            else:\n",
    "                at_freq_dict[match] = 1\n",
    "        \n",
    "    line = re.sub(pattern, ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(line):\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    for match in matches:\n",
    "        line = re.sub(match, ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(line):\n",
    "    # replace everything to ' ' except alphanumeric character, whitespace, apostrophe, hashtag\n",
    "    return re.sub(r'[^\\w\\s\\'#]', ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 17.5 ms, total: 4.59 s\n",
      "Wall time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate cleansed_data beforehand\n",
    "cleansed_data = []\n",
    "for tweet in data:\n",
    "    # remove_retweet_prefix \n",
    "    line = remove_retweet_prefix(tweet)\n",
    "    # remove hashtag\n",
    "    line = remove_hashtag(line)\n",
    "    # remove @...\n",
    "    line = remove_at(line)\n",
    "    # remove url\n",
    "    line = remove_url(line)\n",
    "    # remove punctuations except apostrophe\n",
    "    line = cleanse(line)\n",
    "    cleansed_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"JLo's dress     \",\n",
       " \"What's making Sofia Vergara's boobs stay like that  Magic  Witchcraft   \",\n",
       " ' Kerry Washington is EVERYTHING  Dying over her Miu Miu gown       ',\n",
       " 'Anne Hathaway has got me living   ',\n",
       " \"Jennifer Lopez's lace dress  Thoughts   \"]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cleansed_data))\n",
    "cleansed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_entities(text):\n",
    "    entities = list(nlp(text).ents)\n",
    "    tags = {}\n",
    "    for entity in entities:\n",
    "        if entity not in tags:\n",
    "            tags[' '.join(t.orth_ for t in entity).strip()]=[entity.label_]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "\n",
    "def find_sentiment_score(line, verbose=False):\n",
    "    sentiment_dict = SentimentIntensityAnalyzer().polarity_scores(sentence)\n",
    "    if verbose:\n",
    "        print(sentiment_dict)\n",
    "    return sentiment_dict['neg'], sentiment_dict['neu'], sentiment_dict['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great place to be when you are in Bangalore.\n",
      "{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'compound': 0.6249}\n",
      "(0.0, 0.661, 0.339)\n",
      "\n",
      "The place was being renovated when I visited so the seating was limited.\n",
      "{'neg': 0.147, 'neu': 0.853, 'pos': 0.0, 'compound': -0.2263}\n",
      "(0.147, 0.853, 0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test  \n",
    "texts = [\"Great place to be when you are in Bangalore.\",\n",
    "            \"The place was being renovated when I visited so the seating was limited.\",\n",
    "            \"Loved the ambience, loved the food\",\n",
    "            \"The food is delicious but not over the top.\",\n",
    "            \"Service - Little slow, probably because too many people.\",\n",
    "            \"The place is not easy to locate\",\n",
    "            \"Mushroom fried rice was tasty\"]\n",
    "  \n",
    "for sentence in texts[:2]:\n",
    "    print(sentence)\n",
    "    print(find_sentiment_score(line, verbose=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve hosts from hosts.ipynb\n",
    "# retrieve nominees from nominees.ipynb\n",
    "# retrieve winners from winners.ipynb\n",
    "# retrieve presenters from presenters.ipynb\n",
    "\n",
    "\n",
    "# example\n",
    "subjects = ['Les Miserables', 'Tina Fey', 'Jay Leno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compound_sentiment(subject, verbose=False):\n",
    "    pattern = re.compile(r'{0}'.format(subject), re.IGNORECASE)\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    pos = 0\n",
    "    num = 0\n",
    "    for line in cleansed_data:\n",
    "        match = re.search(pattern, line.lower())\n",
    "        if match:\n",
    "            if verbose:\n",
    "                # print the first 10 occurrences\n",
    "                if num < 10:\n",
    "                    print(tweet)\n",
    "                    print(line)\n",
    "                    print(tags)\n",
    "                    print()\n",
    "\n",
    "            neg_, neu_, pos_ = find_sentiment_score(line)\n",
    "            neg += neg_\n",
    "            neu += neu_\n",
    "            pos += pos_\n",
    "            num += 1\n",
    "            \n",
    "    \n",
    "    print('subject:', subject)\n",
    "    print('num of matches:', num)\n",
    "    print('negative: {0:.4f} \\t neutral: {1:.4f} \\t positive: {2:.4f}'.format(neg, neu, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: Les Miserables\n",
      "num of matches: 2539\n",
      "negative: 373.2330 \t neutral: 2165.7670 \t positive: 0.0000\n",
      "\n",
      "subject: Tina Fey\n",
      "num of matches: 5847\n",
      "negative: 859.5090 \t neutral: 4987.4910 \t positive: 0.0000\n",
      "\n",
      "subject: Jay Leno\n",
      "num of matches: 171\n",
      "negative: 25.1370 \t neutral: 145.8630 \t positive: 0.0000\n",
      "\n",
      "CPU times: user 54.5 s, sys: 62.8 ms, total: 54.5 s\n",
      "Wall time: 54.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# speed may be a big problem for this part\n",
    "# need to compare its performance with textblob\n",
    "for subject in subjects:\n",
    "    calculate_compound_sentiment(subject, verbose=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.596, 'pos': 0.404, 'compound': 0.5242}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from spacy.tokens import Doc\n",
    "def polarity_scores(doc):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(doc.text) \n",
    "Doc.set_extension('polarity_scores', getter=polarity_scores)\n",
    " \n",
    "text = nlp(\"Really Whaaat event apple nice! it!\")\n",
    "print(text._.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
