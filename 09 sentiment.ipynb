{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 747 ms, sys: 107 ms, total: 854 ms\n",
      "Wall time: 854 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "year = 2013\n",
    "df = pd.read_json(path_or_buf='gg{0}.json'.format(year))\n",
    "# df = pd.read_json(path_or_buf='gg2015.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174643"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data if necessary\n",
    "data = df['text']\n",
    "sample_size = 200000\n",
    "if len(df) > sample_size:\n",
    "    data = data.sample(n=sample_size)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174643\n",
      "125585\n",
      "CPU times: user 3.46 s, sys: 16.6 ms, total: 3.48 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "retweets_freq_dict = {}\n",
    "\n",
    "def remove_retweet_prefix(line):\n",
    "    # find 'RT @abc: ' where abc's length is arbitrary\n",
    "    pattern = re.compile(r'\\bRT @([\\w\\'/]*)\\b: ') \n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        # store corresponding retweet without 'RT @' prefix\n",
    "        string = match.group()[4:]\n",
    "        if string in retweets_freq_dict:\n",
    "            retweets_freq_dict[string] += 1\n",
    "        else:\n",
    "            retweets_freq_dict[string] = 1\n",
    "    return re.sub(pattern, ' ', line)\n",
    "\n",
    "hashtag_freq_dict = {}\n",
    "\n",
    "def remove_hashtag(line):\n",
    "    pattern = re.compile(r'#([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in hashtag_freq_dict:\n",
    "                hashtag_freq_dict[match] += 1\n",
    "            else:\n",
    "                hashtag_freq_dict[match] = 1\n",
    "    return re.sub(pattern, ' ', line)\n",
    "\n",
    "at_freq_dict = {}\n",
    "\n",
    "def remove_at(line):\n",
    "    pattern = re.compile(r'@([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in at_freq_dict:\n",
    "                at_freq_dict[match] += 1\n",
    "            else:\n",
    "                at_freq_dict[match] = 1\n",
    "    return re.sub(pattern, ' ', line)\n",
    "\n",
    "def remove_url(line):\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b')\n",
    "    return re.sub(pattern, ' ', line)\n",
    "\n",
    "def cleanse(line):\n",
    "    # replace everything to ' ' except alphanumeric character, whitespace, apostrophe, hashtag\n",
    "    return re.sub(r'[^\\w\\s\\'#]', ' ', line)\n",
    "\n",
    "CLEANSED_DATA = []\n",
    "for tweet in data:\n",
    "    line = remove_retweet_prefix(tweet)\n",
    "    line = remove_hashtag(line)\n",
    "    line = remove_at(line)\n",
    "    line = remove_url(line)\n",
    "    line = cleanse(line)\n",
    "    CLEANSED_DATA.append(line)\n",
    "    \n",
    "# remove redundancies after processing retweets\n",
    "print(len(CLEANSED_DATA))\n",
    "CLEANSED_DATA = list(set(CLEANSED_DATA))\n",
    "print(len(CLEANSED_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Julianne Moore representing Tom Ford  Best dressed of the night  hands down   ',\n",
       " 'LINCOLN    Como siempre Steven Spielberg haciendo Historia   ',\n",
       " 'amo amo amo amo amo os velhinhos do     hsuahsuahsua',\n",
       " \"       excuse but I need about 6 minutes to Masterbate to JLO's ass in this dress\",\n",
       " 'I went 21 25   ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cleansed_data))\n",
    "cleansed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded awards 2013-2015\n",
    "awards = ['cecil b. demille award', 'best motion picture - drama', \n",
    "          'best performance by an actress in a motion picture - drama', \n",
    "          'best performance by an actor in a motion picture - drama', \n",
    "          'best motion picture - comedy or musical', \n",
    "          'best performance by an actress in a motion picture - comedy or musical', \n",
    "          'best performance by an actor in a motion picture - comedy or musical', \n",
    "          'best animated feature film', \n",
    "          'best foreign language film', \n",
    "          'best performance by an actress in a supporting role in a motion picture', \n",
    "          'best performance by an actor in a supporting role in a motion picture', \n",
    "          'best director - motion picture', \n",
    "          'best screenplay - motion picture', \n",
    "          'best original score - motion picture', \n",
    "          'best original song - motion picture', \n",
    "          'best television series - drama', \n",
    "          'best performance by an actress in a television series - drama', \n",
    "          'best performance by an actor in a television series - drama', \n",
    "          'best television series - comedy or musical', \n",
    "          'best performance by an actress in a television series - comedy or musical', \n",
    "          'best performance by an actor in a television series - comedy or musical', \n",
    "          'best mini-series or motion picture made for television', \n",
    "          'best performance by an actress in a mini-series or motion picture made for television', \n",
    "          'best performance by an actor in a mini-series or motion picture made for television', \n",
    "          'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television', \n",
    "          'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']\n",
    "\n",
    "stop_words = set()\n",
    "awards_words = set()\n",
    "for award in awards:\n",
    "    awards_words |= set(cleanse(award).split())\n",
    "\n",
    "stop_words |= awards_words\n",
    "stop_words |= {'award'}\n",
    "stop_words |= {'awards'}\n",
    "stop_words |= {'tv'}\n",
    "stop_words |= {'movie'}\n",
    "stop_words |= {'movies'}\n",
    "stop_words |= {'win'}\n",
    "stop_words |= {'wins'}\n",
    "stop_words |= {'winner'}\n",
    "stop_words |= {'winners'}\n",
    "stop_words |= {'congrats'}\n",
    "stop_words |= {'congratulations'}\n",
    "stop_words |= {'golden'}\n",
    "stop_words |= {'globe'}\n",
    "stop_words |= {'globes'}\n",
    "stop_words |= {'rt'}\n",
    "stop_words |= {'{0}'.format(year)}\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "\n",
    "def find_sentiment_score(line, verbose=False):\n",
    "    sentiment_dict = SentimentIntensityAnalyzer().polarity_scores(sentence)\n",
    "    if verbose:\n",
    "        print(sentiment_dict)\n",
    "    return sentiment_dict['neg'], sentiment_dict['neu'], sentiment_dict['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve hosts from hosts.ipynb\n",
    "# retrieve nominees from nominees.ipynb\n",
    "# retrieve winners from winners.ipynb\n",
    "# retrieve presenters from presenters.ipynb\n",
    "\n",
    "\n",
    "# example\n",
    "subjects = ['Les Miserables', 'Tina Fey', 'Jay Leno']\n",
    "subjects = ['Tina Fey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# reference: https://spacy.io/api/annotation\n",
    "def identify_entities_pos(text, stop_words):\n",
    "    tags = {}\n",
    "    for ent in nlp(text):\n",
    "        entity = ent.text.strip()\n",
    "        if entity not in tags and len(entity) > 1:\n",
    "            # remove stopwords\n",
    "            entity_split = [w for w in entity.split() if w.lower() not in stop_words]            \n",
    "            if len(entity_split) != 0:\n",
    "                entity = ' '.join(entity_split)\n",
    "                if (len(entity.split()) == 1 and entity.lower() == 'the') or len(entity) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    tags[entity]=[ent.tag_]\n",
    "                \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN NNP nsubj\n",
      "is VERB VBZ ROOT\n",
      "so ADV RB advmod\n",
      "pretty ADJ JJ acomp\n",
      "{'Exam': ['NN'], 'is': ['VBZ'], 'so': ['RB'], 'difficult': ['JJ']}\n",
      "JJ\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "doc = nlp(u'Apple is so pretty')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_)\n",
    "    \n",
    "tags = identify_entities_pos('Exam is so difficult!', stop_words)\n",
    "print(tags)\n",
    "print(tags['difficult'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiments(subject, verbose=False):\n",
    "    pattern = re.compile(r'\\b{0}\\b'.format(subject), re.IGNORECASE)\n",
    "    num = 0\n",
    "    sentiment_freq_dict = {}\n",
    "\n",
    "    for line in cleansed_data:\n",
    "        match = re.search(pattern, line.lower())\n",
    "        if match:\n",
    "            tags = identify_entities_pos(line, stop_words)\n",
    "            for entity in tags.keys():\n",
    "                if tags[entity][0] == 'JJ':\n",
    "                    if entity not in sentiment_freq_dict:\n",
    "                        sentiment_freq_dict[entity] = 1\n",
    "                    else:\n",
    "                        sentiment_freq_dict[entity] += 1\n",
    "                \n",
    "            if verbose:\n",
    "                # print the first 10 occurrences\n",
    "                if num < 10:\n",
    "                    print(line)\n",
    "\n",
    "                    \n",
    "            num += 1\n",
    "            if num == 500:\n",
    "                break\n",
    "            \n",
    "    print('subject:', subject)\n",
    "    print('num of matches:', num)\n",
    "    \n",
    "    top_sentiments = sorted(sentiment_freq_dict.items(), key=lambda pair: pair[1], reverse=True)[:3]\n",
    "    top_sentiments = [pair[0] for pair in top_sentiments]\n",
    "    return top_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: tina fey\n",
      "num of matches: 500\n",
      "CPU times: user 16.9 s, sys: 1.88 s, total: 18.8 s\n",
      "Wall time: 3.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hilarious', 'funny', 'amazing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "find_sentiments('tina fey', verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
