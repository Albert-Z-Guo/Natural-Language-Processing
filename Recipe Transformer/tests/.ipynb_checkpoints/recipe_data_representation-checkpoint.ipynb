{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "import requests\n",
    "import unidecode\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def tokenize(line):\n",
    "    return [(token.text, token.tag_) for token in nlp(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allrecipes.com/recipe/23988/simple-spinach-lasagna/?internalSource=streams&referringId=87&referringContentType=Recipe%20Hub&clickId=st_trending_s'\n",
    "\n",
    "# test\n",
    "# url = 'https://www.allrecipes.com/recipe/235874/copycat-panera-broccoli-cheddar-soup/?clickId=right%20rail1&internalSource=rr_feed_recipe_sb&referringId=23988%20referringContentType%3Drecipe'\n",
    "# url = 'https://www.allrecipes.com/recipe/246141/pad-thai-with-tofu/'\n",
    "# url = 'https://www.allrecipes.com/recipe/221286/traditional-mexican-guacamole'\n",
    "url = 'https://www.allrecipes.com/recipe/59661/spinach-enchiladas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 m\n",
      "20 m\n"
     ]
    }
   ],
   "source": [
    "def extract_time(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    times = set([element.text.strip() for element in soup.find_all(class_='prepTime__item')])\n",
    "    # remove uncessary elements\n",
    "    times.remove('')\n",
    "    prep_time = None\n",
    "    cook_time = None\n",
    "    for time in times:\n",
    "        if 'prep' in time.lower():\n",
    "            prep_time = time[4:]\n",
    "        if 'cook' in time.lower():\n",
    "            cook_time = time[4:]\n",
    "    return prep_time, cook_time\n",
    "\n",
    "# test\n",
    "prep_time, cook_time = extract_time(url)\n",
    "print(prep_time)\n",
    "print(cook_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_minutes(cook_time):\n",
    "    if cook_time is None:\n",
    "        return 0\n",
    "    if 'h' in cook_time:\n",
    "        hour_index = cook_time.index('h')\n",
    "        print(hour_index)\n",
    "        hours = int(cook_time[:hour_index].strip())\n",
    "        if 'm' in cook_time:\n",
    "            minutes = int(cook_time[hour_index+1 : -1].strip())\n",
    "        else:\n",
    "            minutes = 0\n",
    "    else:\n",
    "        hours = 0\n",
    "        minutes = int(cook_time[: -1].strip())\n",
    "    return 60*hours + minutes\n",
    "\n",
    "# test\n",
    "convert_to_minutes(cook_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spinach Enchiladas'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recipe_name(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup.find_all(\"h1\", {\"class\": \"recipe-summary__h1\"})[0].text\n",
    "\n",
    "# test\n",
    "get_recipe_name(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Preheat the oven to 375 degrees F (190 degrees C).', 'Melt butter in a saucepan over medium heat. Add garlic and onion; cook for a few minutes until fragrant, but not brown. Stir in spinach, and cook for about 5 more minutes. Remove from the heat, and mix in ricotta cheese, sour cream, and 1 cup of Monterey Jack cheese.', 'In a skillet over medium heat, warm tortillas one at a time until flexible, about 15 seconds. Spoon about 1/4 cup of the spinach mixture onto the center of each tortilla. Roll up, and place seam side down in a 9x13 inch baking dish. Pour enchilada sauce over the top, and sprinkle with the remaining cup of Monterey Jack.', 'Bake for 15 to 20 minutes in the preheated oven, until sauce is bubbling and cheese is lightly browned at the edges.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1 (10 ounce) package frozen chopped spinach , thawed, drained and squeezed dry',\n",
       " '1 (19 ounce) can enchilada sauce',\n",
       " '1 cup ricotta cheese',\n",
       " '1 tablespoon butter',\n",
       " '1/2 cup sliced green onions',\n",
       " '1/2 cup sour cream',\n",
       " '10 (6 inch) corn tortillas',\n",
       " '2 cloves garlic, minced',\n",
       " '2 cups shredded Monterey Jack cheese'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ingredient_list_and_directions(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # extract ingredients section from the webpage\n",
    "    ingredients = [element.label.text.strip() for element in soup.find_all(class_='checkList__line')]\n",
    "    \n",
    "    # remove exceptions like 'topping:'\n",
    "    for i in ingredients:\n",
    "        if ':' in i:\n",
    "            ingredients.remove(i)\n",
    "    ingredients = set(ingredients)\n",
    "    \n",
    "    # remove unnecessary elements\n",
    "    unnecessary = ['', 'Add all ingredients to list']\n",
    "    for i in unnecessary:\n",
    "        if i in ingredients:\n",
    "            ingredients.remove(i)\n",
    "            \n",
    "    # extract directions section from the webpage\n",
    "    directions = [element.text.strip() for element in soup.find_all(class_='recipe-directions__list--item')]\n",
    "    # remove unnecessary elements\n",
    "    directions.remove('')\n",
    "    return ingredients, directions\n",
    "\n",
    "# test\n",
    "ingredients, directions = get_ingredient_list_and_directions(url)\n",
    "print(directions)\n",
    "ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical(line):\n",
    "    # replace everything to '' except whitespace, alphanumeric character\n",
    "    line = re.sub(r'[^\\w\\s]', '', line)\n",
    "    token_tag_pairs = tokenize(line)\n",
    "    for pair in token_tag_pairs:\n",
    "        # if the word is not numerical\n",
    "        if not pair[1] == \"CD\":\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def nouns_only(line):\n",
    "    adjective_type_exceptions = ['ground', 'skinless', 'boneless']\n",
    "    noun_type_exceptions = ['parsley', 'garlic', 'chili', 'chile', 'substitute', 'cream', 'flanken', 'cilantro', 'such']\n",
    "    # replace everything to '' except whitespace, alphanumeric character\n",
    "    line = re.sub(r'[^\\w\\s]', '', line)\n",
    "    token_tag_pairs = tokenize(line)\n",
    "    for pair in token_tag_pairs:\n",
    "        # if the word is not a noun or cardinal number\n",
    "        if (not (pair[1] == \"NN\" or pair[1] == \"NNS\") or pair[0] in adjective_type_exceptions) and pair[0] not in noun_type_exceptions:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brackets(line):\n",
    "    # find '(abc)' where 'abc' is in arbitrary length and 'abc' does not contain brackets\n",
    "    pattern = re.compile(r'\\([^\\(\\)]*\\)') \n",
    "    match = re.findall(pattern, line)\n",
    "    if len(match) != 0:\n",
    "        return match\n",
    "    \n",
    "def extract_preparation(line):\n",
    "    # find ', abc' or ' - abc' where 'abc' is in arbitrary length\n",
    "#     match = re.findall(re.compile(r'\\b[,-] [^\\(\\)]*'), line)\n",
    "    match = re.findall(re.compile(r'[^.], .*| - .*'), line)\n",
    "    if len(match) != 0:\n",
    "        if match[-1][-1] == ')':\n",
    "            return match[-1][1:-1]\n",
    "        else:\n",
    "            return match[-1][1:]\n",
    "    \n",
    "def extract_descriptor(ingredient_name):\n",
    "    noun_type_exceptions = ['parsley', 'garlic', 'chili', 'chile', 'substitute', 'cream', 'flanken', 'such']\n",
    "    adjective_type_exceptions = ['ground', 'skinless', 'boneless']\n",
    "    descriptor = []\n",
    "    token_tag_pairs = []\n",
    "    \n",
    "    for element in ingredient_name.split():\n",
    "        # treat compound word with hyphen as an adjective\n",
    "        if '-' in element:\n",
    "            token_tag_pairs.append((element, 'JJ'))\n",
    "        else:\n",
    "            token_tag_pairs.append([(token.text, token.tag_) for token in nlp(element)][0])\n",
    "            \n",
    "    for pair in token_tag_pairs:\n",
    "        # if the word is an adjective, an adverb, or a past participle of a verb, or exception like 'ground'\n",
    "        if pair[1] == \"JJ\" or pair[1] == \"RB\" or pair[1] == \"VBN\" or pair[0] in adjective_type_exceptions:\n",
    "            if pair[0] not in noun_type_exceptions:\n",
    "                descriptor.append(pair[0])\n",
    "    if len(descriptor) != 0:\n",
    "        return ' '.join(descriptor)\n",
    "        \n",
    "def extract_all(line):\n",
    "    noun_type_exceptions = ['can', 'tablespoon', 'oz', 'clove']\n",
    "    not_measurements = ['jalapeno', 'roma']\n",
    "    measurement = None\n",
    "    quantity_in_brackets = None\n",
    "    quantity_split = []\n",
    "    pre_preparation = []\n",
    "    \n",
    "    # extract preparation\n",
    "    preparation = extract_preparation(line)\n",
    "    if preparation:\n",
    "        line = line.replace(preparation, '')\n",
    "        # remove 'x, ' prefix\n",
    "        preparation = preparation[2:].strip()\n",
    "    \n",
    "    # extract backets\n",
    "    brackets = extract_brackets(line)\n",
    "    if brackets:\n",
    "        # check the first bracket\n",
    "        # if no numerical value or line_split length > 3 \n",
    "        if not any(char.isdigit() for char in brackets[0]) or len(brackets[0].split()) > 3:\n",
    "            pre_preparation.append(brackets[0][1:-1])\n",
    "        else:\n",
    "            quantity_in_brackets = brackets[0]\n",
    "        # check the rest brackets if any\n",
    "        if len(brackets) > 1:\n",
    "            for b in brackets[1:]:\n",
    "                pre_preparation.append(b[1:-1])\n",
    "        for b in brackets:\n",
    "            line = re.sub(r'\\({0}\\)'.format(b), '', line)  \n",
    "        \n",
    "    line_split = line.split()\n",
    "    # extract quantity from the first word if the word contains a digit\n",
    "    if any(char.isdigit() for char in line_split[0]):\n",
    "        quantity_split.append(line_split[0])\n",
    "    \n",
    "        # extract quantity from the second word if the word contains a digit\n",
    "        if any(char.isdigit() for char in line_split[1]):\n",
    "            quantity_split.append(line_split[1])\n",
    "            # measurement index\n",
    "            i = 2\n",
    "            # check for special case\n",
    "            if line_split[2] == 'oz':\n",
    "                quantity_split.append('oz')\n",
    "                i = 3\n",
    "            # check measurement type\n",
    "            if (nouns_only(line_split[i]) or line_split[i] in noun_type_exceptions) and line_split[i] not in not_measurements:\n",
    "                measurement = line_split[i]\n",
    "        else:\n",
    "            # check line_split length and measurement type for cases like '1 egg' or '1/2 onion, chopped' or '1 large tomato, seeded and chopped'\n",
    "            if len(line_split) > 2 and (nouns_only(line_split[1]) or line_split[1] in noun_type_exceptions) and line_split[1] not in not_measurements:\n",
    "                measurement = line_split[1]\n",
    "        line = re.sub(r'{0}'.format(' '.join(quantity_split)), '', line)\n",
    "    \n",
    "    if measurement:\n",
    "        line = re.sub(r'{0}'.format(measurement), '', line)\n",
    "    \n",
    "    # append quantity in backets at the end\n",
    "    if quantity_in_brackets:\n",
    "        quantity_split.append(quantity_in_brackets)\n",
    "    \n",
    "    ingredient_name = line.strip()\n",
    "\n",
    "    # extract descriptor from ingredient_name\n",
    "    descriptor = extract_descriptor(ingredient_name)\n",
    "\n",
    "    # extract ingredient\n",
    "    ingredient = ingredient_name\n",
    "    if descriptor:\n",
    "        for i in descriptor.split():\n",
    "            ingredient = re.sub(r'[ ]?\\b{0}\\b'.format(i), '', ingredient).strip()\n",
    "    if ingredient == '':\n",
    "        ingredient = ingredient_name\n",
    "\n",
    "    # add prepreparation to descriptor or preparation\n",
    "    if pre_preparation:\n",
    "        if descriptor is None:\n",
    "            descriptor = ', '.join(pre_preparation)\n",
    "        else:\n",
    "            descriptor += ', ' + ', '.join(pre_preparation)\n",
    "    \n",
    "    # add 'to taste' to quantity if any\n",
    "    if 'to taste' in ingredient:\n",
    "        quantity_split.append('to taste')\n",
    "    quantity = ' '.join(quantity_split)\n",
    "    if quantity == '':\n",
    "        quantity = None\n",
    "    \n",
    "    # remove ' to taste' in ingredient if any\n",
    "    ingredient = re.sub(r'(or)? to taste', '', ingredient)\n",
    "    ingredient = ' '.join(ingredient.split())\n",
    "    \n",
    "    # if the extracted ingredient is not noun\n",
    "    if not nouns_only(ingredient):\n",
    "        ingredient_name = ingredient\n",
    "        if preparation:\n",
    "            ingredient_name += ' ' + preparation\n",
    "        ingredient_name = ingredient_name.replace(' -', ',')\n",
    "        preparation = extract_preparation(ingredient_name)\n",
    "        ingredient_name = re.sub(r'{0}'.format(preparation), '', ingredient_name)\n",
    "        if preparation:\n",
    "            preparation = preparation[2:].strip()\n",
    "        descriptor = extract_descriptor(ingredient_name)\n",
    "        ingredient = ingredient_name\n",
    "        if descriptor:\n",
    "            for i in descriptor.split():\n",
    "                ingredient = re.sub(r'[ ]?\\b{0}\\b'.format(i), '', ingredient).strip()\n",
    "            if ingredient == '':\n",
    "                ingredient = ingredient_name\n",
    "    \n",
    "    return quantity, measurement, descriptor, ingredient, preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cup ricotta cheese\n",
      "\t quantity   : 1\n",
      "\t measurement: cup\n",
      "\t descriptor : ricotta\n",
      "\t ingredient : cheese\n",
      "\t preparation: None\n",
      "\n",
      "1 tablespoon butter\n",
      "\t quantity   : 1\n",
      "\t measurement: tablespoon\n",
      "\t descriptor : None\n",
      "\t ingredient : butter\n",
      "\t preparation: None\n",
      "\n",
      "2 cloves garlic, minced\n",
      "\t quantity   : 2\n",
      "\t measurement: cloves\n",
      "\t descriptor : None\n",
      "\t ingredient : garlic\n",
      "\t preparation: minced\n",
      "\n",
      "2 cups shredded Monterey Jack cheese\n",
      "\t quantity   : 2\n",
      "\t measurement: cups\n",
      "\t descriptor : None\n",
      "\t ingredient : Monterey Jack cheese\n",
      "\t preparation: None\n",
      "\n",
      "1 (10 ounce) package frozen chopped spinach , thawed, drained and squeezed dry\n",
      "\t quantity   : 1 (10 ounce)\n",
      "\t measurement: package\n",
      "\t descriptor : frozen chopped\n",
      "\t ingredient : spinach\n",
      "\t preparation: thawed, drained and squeezed dry\n",
      "\n",
      "10 (6 inch) corn tortillas\n",
      "\t quantity   : 10 (6 inch)\n",
      "\t measurement: corn\n",
      "\t descriptor : None\n",
      "\t ingredient : tortillas\n",
      "\t preparation: None\n",
      "\n",
      "1/2 cup sour cream\n",
      "\t quantity   : 1/2\n",
      "\t measurement: cup\n",
      "\t descriptor : sour\n",
      "\t ingredient : cream\n",
      "\t preparation: None\n",
      "\n",
      "1 (19 ounce) can enchilada sauce\n",
      "\t quantity   : 1 (19 ounce)\n",
      "\t measurement: can\n",
      "\t descriptor : enchilada\n",
      "\t ingredient : sauce\n",
      "\t preparation: None\n",
      "\n",
      "1/2 cup sliced green onions\n",
      "\t quantity   : 1/2\n",
      "\t measurement: cup\n",
      "\t descriptor : sliced green\n",
      "\t ingredient : onions\n",
      "\t preparation: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decompose_ingredients(ingredients):\n",
    "    for line in ingredients:\n",
    "        quantity, measurement, descriptor, ingredient, preparation = extract_all(line)\n",
    "        print(line)\n",
    "        print('\\t quantity   :', quantity)\n",
    "        print('\\t measurement:', measurement)\n",
    "        print('\\t descriptor :', descriptor)\n",
    "        print('\\t ingredient :', ingredient)\n",
    "        print('\\t preparation:', preparation)\n",
    "        print()\n",
    "\n",
    "# test\n",
    "decompose_ingredients(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bake',\n",
       " 'baking',\n",
       " 'butter',\n",
       " 'center',\n",
       " 'cheese',\n",
       " 'cream',\n",
       " 'cup',\n",
       " 'degrees',\n",
       " 'dish',\n",
       " 'edges',\n",
       " 'enchilada',\n",
       " 'garlic',\n",
       " 'heat',\n",
       " 'inch',\n",
       " 'minutes',\n",
       " 'mixture',\n",
       " 'onion',\n",
       " 'oven',\n",
       " 'sauce',\n",
       " 'saucepan',\n",
       " 'seam',\n",
       " 'seconds',\n",
       " 'side',\n",
       " 'skillet',\n",
       " 'spinach',\n",
       " 'time',\n",
       " 'top',\n",
       " 'tortilla',\n",
       " 'tortillas'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_directions_nouns(directions):\n",
    "    directions_nouns = set()\n",
    "    if isinstance(directions, str):\n",
    "        directions = [directions]\n",
    "    for direction in directions:\n",
    "        sentences = sent_tokenize(direction)\n",
    "        for sentence in sentences:\n",
    "            # check for special cases where spaCy cannot recognize well\n",
    "            if ' oven' in sentence:\n",
    "                directions_nouns |= {'oven'}\n",
    "#             print(sentence)\n",
    "            token_tag_pairs = tokenize(sentence)\n",
    "            for pair in token_tag_pairs:    \n",
    "                # avoid case like 'degrees C'\n",
    "                if len(pair[0]) > 1:\n",
    "                    if (pair[1] == 'NN' or pair[1] == 'NNS') and pair[0] != 'ground':\n",
    "                        directions_nouns |= {pair[0]}\n",
    "#         print('---------')\n",
    "    return directions_nouns\n",
    "    \n",
    "directions_nouns = extract_directions_nouns(directions)\n",
    "directions_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spong'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# test\n",
    "stemmer.stem('Sponges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag',\n",
       " 'bin',\n",
       " 'blender',\n",
       " 'board',\n",
       " 'bowl',\n",
       " 'coland',\n",
       " 'contain',\n",
       " 'cup',\n",
       " 'dish',\n",
       " 'foil',\n",
       " 'grater',\n",
       " 'guard',\n",
       " 'juicer',\n",
       " 'knife',\n",
       " 'ladl',\n",
       " 'masher',\n",
       " 'mitt',\n",
       " 'open',\n",
       " 'pan',\n",
       " 'paper',\n",
       " 'peeler',\n",
       " 'pot',\n",
       " 'press',\n",
       " 'rack',\n",
       " 'saucepan',\n",
       " 'scale',\n",
       " 'sharpen',\n",
       " 'shear',\n",
       " 'skillet',\n",
       " 'spatula',\n",
       " 'spinner',\n",
       " 'spong',\n",
       " 'spoon',\n",
       " 'steel',\n",
       " 'stockpot',\n",
       " 'thermomet',\n",
       " 'tong',\n",
       " 'towel',\n",
       " 'tray',\n",
       " 'trivet',\n",
       " 'whisk'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_tools_set():\n",
    "    try:\n",
    "        with open('data/tools.pickle', 'rb') as file:\n",
    "            tools = pickle.load(file)\n",
    "#             print('loaded tools set successfully')\n",
    "    except:\n",
    "        url = 'https://www.mealime.com/kitchen-essentials-list'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        tools = [element.text for element in soup.find_all(class_='anchor-button')]\n",
    "        # reduce each tool to its last word\n",
    "        print(tools)\n",
    "        tools = set([stemmer.stem(tool.split()[-1].strip()) for tool in tools])\n",
    "        \n",
    "        # save retrieved data\n",
    "        with open('data/tools.pickle', 'wb') as file:\n",
    "            pickle.dump(tools, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return tools\n",
    "\n",
    "retrieve_tools_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup', 'dish', 'saucepan', 'skillet'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_tools(directions_nouns):\n",
    "    tools = retrieve_tools_set()\n",
    "    directions_tools = set()\n",
    "    for noun in directions_nouns:\n",
    "        if stemmer.stem(noun) in tools:\n",
    "            directions_tools |= {noun}\n",
    "    return directions_tools\n",
    "\n",
    "extract_tools(directions_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saute'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "accented_string = 'sauté'\n",
    "unidecode.unidecode(accented_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bake',\n",
       " 'blanch',\n",
       " 'boil',\n",
       " 'brais',\n",
       " 'broil',\n",
       " 'deep-fri',\n",
       " 'grill',\n",
       " 'pan-fri',\n",
       " 'poach',\n",
       " 'roast',\n",
       " 'saut',\n",
       " 'sear',\n",
       " 'simmer',\n",
       " 'steam',\n",
       " 'stew'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_cooking_methods_set():\n",
    "    try:\n",
    "        with open('data/cooking_methods.pickle', 'rb') as file:\n",
    "            cooking_methods = pickle.load(file)\n",
    "#             print('loaded cooking_methods set successfully')\n",
    "    except:\n",
    "        url = 'https://www.thedailymeal.com/cook/15-basic-cooking-methods-you-need-know-slideshow/slide-13'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        cooking_methods = [element.h2.text for element in soup.find_all(class_='image-title slide-title')]\n",
    "        cooking_methods = set([stemmer.stem(unidecode.unidecode(method.strip())) for method in cooking_methods])\n",
    "        \n",
    "        # save retrieved data\n",
    "        with open('data/cooking_methods.pickle', 'wb') as file:\n",
    "            pickle.dump(cooking_methods, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    return cooking_methods\n",
    "\n",
    "# test\n",
    "methods = retrieve_cooking_methods_set()\n",
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bain-mari',\n",
       " 'bake',\n",
       " 'barbecu',\n",
       " 'bast',\n",
       " 'blanch',\n",
       " 'boil',\n",
       " 'bone',\n",
       " 'brine',\n",
       " 'can',\n",
       " 'caramel',\n",
       " 'chiffonad',\n",
       " 'chop',\n",
       " 'cockaign',\n",
       " 'cream',\n",
       " 'cube',\n",
       " 'deglaz',\n",
       " 'degorg',\n",
       " 'dredg',\n",
       " 'dri',\n",
       " 'ferment',\n",
       " 'fri',\n",
       " 'grill',\n",
       " 'julien',\n",
       " 'marin',\n",
       " 'minc',\n",
       " 'pan-fri',\n",
       " 'pickl',\n",
       " 'poach',\n",
       " 'roast',\n",
       " 'rub',\n",
       " 'sauté',\n",
       " 'scald',\n",
       " 'shir',\n",
       " 'simmer',\n",
       " 'skill',\n",
       " 'slice',\n",
       " 'smoke',\n",
       " 'sous-vid',\n",
       " 'steam',\n",
       " 'stew',\n",
       " 'stir-fri',\n",
       " 'storag',\n",
       " 'temper',\n",
       " 'test'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_other_cooking_methods_set():\n",
    "    try:\n",
    "        with open('data/other_cooking_methods.pickle', 'rb') as file:\n",
    "            other_cooking_methods = pickle.load(file)\n",
    "#             print('loaded other_cooking_methods set successfully')\n",
    "    except:\n",
    "        url = 'https://en.wikibooks.org/wiki/Cookbook:Cooking_Techniques'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        unwanted = ['Contents', '[', 'edit', ']', '\\n']\n",
    "        other_cooking_methods = set()\n",
    "        dump = soup.find_all(class_='mw-parser-output')\n",
    "        for i in dump:\n",
    "            for j in i.contents:\n",
    "                if hasattr(j, 'contents'):\n",
    "                    for k in j.contents:\n",
    "                        if hasattr(k, 'contents'):\n",
    "                            for l in k.contents:\n",
    "                                if hasattr(l, 'contents'):\n",
    "                                    for method in l:\n",
    "    #                                     print(method.string)\n",
    "                                        if method.string is not None and method not in unwanted:\n",
    "                                            other_cooking_methods |= {stemmer.stem(method.string.split()[-1])}\n",
    "\n",
    "        # remove uncessary methods after complexity reduction\n",
    "        other_cooking_methods.remove('cook')\n",
    "        other_cooking_methods.remove('chocol')\n",
    "        \n",
    "        # save retrieved data\n",
    "        with open('data/other_cooking_methods.pickle', 'wb') as file:\n",
    "            pickle.dump(other_cooking_methods, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    return other_cooking_methods\n",
    "\n",
    "# test\n",
    "other_methods = retrieve_other_cooking_methods_set()\n",
    "other_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add',\n",
       " 'cook',\n",
       " 'mix',\n",
       " 'place',\n",
       " 'pour',\n",
       " 'preheat',\n",
       " 'remove',\n",
       " 'roll',\n",
       " 'spoon',\n",
       " 'sprinkle',\n",
       " 'stir'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_directions_verbs(directions):\n",
    "    directions_verbs = set()\n",
    "    if isinstance(directions, str):\n",
    "        directions = [directions]\n",
    "    for direction in directions:\n",
    "        sentences = sent_tokenize(direction)\n",
    "        for sentence in sentences:\n",
    "#             print(sentence)\n",
    "            token_tag_pairs = tokenize(sentence)\n",
    "            for pair in token_tag_pairs:    \n",
    "                if pair[1] == 'VB':\n",
    "                    directions_verbs |= {pair[0].lower()}\n",
    "#         print('---------')\n",
    "    return directions_verbs\n",
    "\n",
    "directions_verbs = extract_directions_verbs(directions)\n",
    "directions_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_methods(directions_verbs):\n",
    "    methods = retrieve_cooking_methods_set()\n",
    "    methods |= retrieve_other_cooking_methods_set()\n",
    "    directions_methods = set()\n",
    "    for verb in directions_verbs:\n",
    "        if stemmer.stem(verb) in methods:\n",
    "            directions_methods |= {verb}\n",
    "    return directions_methods\n",
    "\n",
    "extract_methods(directions_verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monterey Jack cheese',\n",
       " 'tortillas',\n",
       " 'spinach',\n",
       " 'garlic',\n",
       " 'butter',\n",
       " 'onions',\n",
       " 'cheese',\n",
       " 'cream',\n",
       " 'sauce']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_directions_ingredients(ingredients):\n",
    "    ingredients_nouns = set()\n",
    "    for line in ingredients:\n",
    "        quantity, measurement, descriptor, ingredient, preparation = extract_all(line)\n",
    "        ingredients_nouns |= {ingredient}\n",
    "        # for better granularity, in case full name is not mentioned\n",
    "        token_tag_pairs = tokenize(ingredient)\n",
    "        for pair in token_tag_pairs:    \n",
    "            if len(pair[0]) > 1:\n",
    "                if (pair[1] == 'NN' or pair[1] == 'NNS') and pair[0] != 'ground':\n",
    "                    ingredients_nouns |= {pair[0]}\n",
    "    # start from the longest\n",
    "    return sorted((list(ingredients_nouns)), key=len)[::-1]\n",
    "\n",
    "extract_directions_ingredients(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ingredients(direction):\n",
    "    ingredients_set = extract_directions_ingredients(ingredients)\n",
    "    direction_ingredients = set()\n",
    "    used = set()\n",
    "    sentences = sent_tokenize(direction)\n",
    "    for sentence in sentences:\n",
    "        for i in ingredients_set:\n",
    "            if i in sentence and i not in used:\n",
    "                direction_ingredients |= {i}\n",
    "                # store used partial word in used\n",
    "                for word in i.split():\n",
    "                    used |= {word}\n",
    "    return direction_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 minute + 15 minutes'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_direction_time(direction):\n",
    "    times = []\n",
    "    for sentence in sent_tokenize(direction):\n",
    "        match = re.findall(re.compile(r'for .* minute[s]?\\b|\\d+ minute[s]?\\b'), sentence)\n",
    "        if len(match) != 0:\n",
    "            for m in match:\n",
    "                times.append(m.replace('for ', ''))\n",
    "    if len(times) == 0:\n",
    "        return None\n",
    "    return ' + '.join(times)\n",
    "\n",
    "# test\n",
    "d = 'Add garlic to the onions and cook an additional 1 minute. Add chicken soup base, water, and potatoes, simmer 15 minutes.'\n",
    "# d = 'Melt butter in a saucepan over medium heat. Add garlic and onion; cook for a few minutes until fragrant, but not brown. Stir in spinach, and cook for about 5 more minutes. Remove from the heat, and mix in ricotta cheese, sour cream, and 1 cup of Monterey Jack cheese.'\n",
    "extract_direction_time(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Direction: Preheat the oven to 375 degrees F (190 degrees C).\n",
      "\tprep time: 20 m\n",
      "---------\n",
      "Step: 2\n",
      "Direction: Melt butter in a saucepan over medium heat. Add garlic and onion; cook for a few minutes until fragrant, but not brown. Stir in spinach, and cook for about 5 more minutes. Remove from the heat, and mix in ricotta cheese, sour cream, and 1 cup of Monterey Jack cheese.\n",
      "\testimated cook time: a few minutes + about 5 more minutes\n",
      "\ttools: saucepan, cup\n",
      "\tingredients: Monterey Jack cheese sauce cream butter spinach garlic\n",
      "---------\n",
      "Step: 3\n",
      "Direction: In a skillet over medium heat, warm tortillas one at a time until flexible, about 15 seconds. Spoon about 1/4 cup of the spinach mixture onto the center of each tortilla. Roll up, and place seam side down in a 9x13 inch baking dish. Pour enchilada sauce over the top, and sprinkle with the remaining cup of Monterey Jack.\n",
      "\testimated cook time: 7 minutes\n",
      "\ttools: skillet, cup, dish\n",
      "\tingredients: sauce spinach tortillas\n",
      "---------\n",
      "Step: 4\n",
      "Direction: Bake for 15 to 20 minutes in the preheated oven, until sauce is bubbling and cheese is lightly browned at the edges.\n",
      "\testimated cook time: 15 to 20 minutes\n",
      "\tingredients: cheese sauce\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "def decompose_steps():\n",
    "    prep_time, cook_time = extract_time(url)\n",
    "    if len(directions) > 1:\n",
    "            average_cook_time_per_step = round(convert_to_minutes(cook_time) / (len(directions) - 1))\n",
    "\n",
    "    for i, direction in enumerate(directions):\n",
    "        print('Step:', i+1)\n",
    "        print('Direction:', direction)\n",
    "        if i == 0:\n",
    "            print('\\tprep time:', prep_time)\n",
    "        else:\n",
    "            if extract_direction_time(direction):\n",
    "                print('\\testimated cook time: ' + extract_direction_time(direction))\n",
    "            else:\n",
    "                print('\\testimated cook time: {0} minutes'.format(average_cook_time_per_step))\n",
    "\n",
    "        single_direction_tools = extract_tools(extract_directions_nouns(direction))\n",
    "        single_direction_methods = extract_methods(extract_directions_verbs(direction))\n",
    "        single_direction_ingredients = extract_ingredients(direction)\n",
    "\n",
    "        if len(single_direction_tools) > 0:\n",
    "            print('\\ttools:', ', '.join(single_direction_tools))\n",
    "        if len(single_direction_methods) > 0:\n",
    "            print('\\tmethods:', ', '.join(single_direction_methods))\n",
    "        if len(single_direction_ingredients) > 0:\n",
    "            print('\\tingredients:', ' '.join(single_direction_ingredients))\n",
    "        print('---------')\n",
    "\n",
    "decompose_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
