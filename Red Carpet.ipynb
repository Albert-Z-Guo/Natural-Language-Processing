{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**determine who was**\n",
    "* best dressed\n",
    "* worst dressed \n",
    "* most controversial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(path_or_buf='gg2013.json')\n",
    "df.head(10)\n",
    "\n",
    "data = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanse(line):\n",
    "    # replace everything to ' ' except whitespace, alphanumeric character, apostrophe, hashtag, @\n",
    "    return re.sub(r'[^\\w\\s\\'#@]', ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('JLo', 'PROPN'), (\"'s\", 'PART'), ('dress', 'NOUN'), (' ', 'SPACE'), ('#', 'SYM'), ('eredcarpet', 'NOUN'), ('#', 'SYM'), ('GoldenGlobes', 'PROPN')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# python -m spacy download en\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(cleanse(data[0]))\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_freq_dict = {}\n",
    "\n",
    "def remove_retweet_prefix(line):\n",
    "    # find 'RT @abc: ' where abc's length is arbitrary\n",
    "    pattern = re.compile(r'\\bRT @([\\w\\'/]*)\\b: ') \n",
    "   \n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        # store corresponding retweet without 'RT @' prefix\n",
    "        string = match.group()[4:]\n",
    "        if string in retweets_freq_dict:\n",
    "            retweets_freq_dict[string] += 1\n",
    "        else:\n",
    "            retweets_freq_dict[string] = 1\n",
    "        \n",
    "    return re.sub(pattern, ' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tina\n"
     ]
    }
   ],
   "source": [
    "def remove_apostrophe(text):\n",
    "    # remove_apostrophe\n",
    "    if text.endswith(\"'s\"):\n",
    "        return text[:-2].strip()\n",
    "    return text\n",
    "\n",
    "# test\n",
    "print(remove_apostrophe(\"Tina 's\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_freq_dict = {}\n",
    "\n",
    "def remove_hashtag(line):\n",
    "    pattern = re.compile(r'#([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in hashtag_freq_dict:\n",
    "                hashtag_freq_dict[match] += 1\n",
    "            else:\n",
    "                hashtag_freq_dict[match] = 1\n",
    "        \n",
    "    line = re.sub(pattern, ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def print_top(n, num):\n",
    "    sorted_nominees = sorted(n.items(), key=lambda e: e[1], reverse=True)\n",
    "    pprint.pprint(sorted_nominees[0:num])\n",
    "#     names = [pair[0] for pair in sorted_nominees]\n",
    "#     pprint.pprint(names[0:num])\n",
    "    print('list length:', len(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_freq_dict = {}\n",
    "\n",
    "def remove_at(line):\n",
    "    pattern = re.compile(r'@([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in at_freq_dict:\n",
    "                at_freq_dict[match] += 1\n",
    "            else:\n",
    "                at_freq_dict[match] = 1\n",
    "        \n",
    "    line = re.sub(pattern, ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tina\n"
     ]
    }
   ],
   "source": [
    "def remove_apostrophe(text):\n",
    "    # remove_apostrophe\n",
    "    if text.endswith(\"'s\"):\n",
    "        return text[:-2].strip()\n",
    "    return text\n",
    "\n",
    "# test\n",
    "print(remove_apostrophe(\"Tina 's\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_freq_dict = {}\n",
    "\n",
    "def remove_hashtag(line):\n",
    "    pattern = re.compile(r'#([\\w\\'/]*)\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    if matches:\n",
    "        # store corresponding hashtag\n",
    "        for match in matches:\n",
    "            if match in hashtag_freq_dict:\n",
    "                hashtag_freq_dict[match] += 1\n",
    "            else:\n",
    "                hashtag_freq_dict[match] = 1\n",
    "        \n",
    "    line = re.sub(pattern, ' ', line)\n",
    "    return line\n",
    "\n",
    "def remove_url(line):\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b')\n",
    "    matches = re.findall(pattern, line)\n",
    "    for match in matches:\n",
    "        line = re.sub(match, ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000000000000001"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# pip3 install TextBlob\n",
    "\n",
    "def get_polarity(line):\n",
    "    blob = TextBlob(line)\n",
    "    for sentence in blob.sentences:\n",
    "#         print(sentence.sentiment.polarity)\n",
    "        return float(sentence.sentiment.polarity)\n",
    "    \n",
    "line = \"Jennifer Lopez's dress is jaw droppingly amazing #GoldenGlobes #redcarpet\"\n",
    "get_polarity(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mfind_names\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_url' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fuzzywuzzy import fuzz\n",
    "from textblob import TextBlob\n",
    "\n",
    "def find_names():\n",
    "    pattern = re.compile(\"(dress)|(wear)|(outfit)|(suit)|(cloth)\", re.IGNORECASE)\n",
    "    # pattern1 = re.compile(\"(\\saward\\s)|(\\sbest\\s)\", re.IGNORECASE)\n",
    "    neg_dict = {}\n",
    "    pos_dict = {}\n",
    "\n",
    "    for line in data:\n",
    "        line = cleanse(line)\n",
    "        line = remove_retweet_prefix(line)\n",
    "        line = remove_at(line)\n",
    "        line = remove_hashtag(line)\n",
    "        line = remove_url(line)\n",
    "        match = pattern.search(line)\n",
    "\n",
    "        if match:\n",
    "            p = get_polarity(line)\n",
    "            doc = nlp(line)\n",
    "            \n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == 'PERSON':\n",
    "                    name = ent.text.strip()\n",
    "                    name = remove_apostrophe(name)\n",
    "                    # not add to list if the entity is null or golden globe related\n",
    "                    if p is None or name == '' or fuzz.ratio(name.lower(), 'golden globes') > 60:\n",
    "                        continue\n",
    "                    if p < 0:\n",
    "                        if name in neg_dict:\n",
    "                            neg_dict[name] += p\n",
    "                        else:\n",
    "                            neg_dict[name] = p\n",
    "                    \n",
    "                    if p > 0:\n",
    "                        if name in pos_dict:\n",
    "                            pos_dict[name] += p\n",
    "                        else:\n",
    "                            pos_dict[name] = p\n",
    "\n",
    "#     pos = {key: value for key, value in persons_dic.items() if value > 10}\n",
    "    # nominees = sorted(nominees.items(), key=lambda e: e[1], reverse=True)\n",
    "    return pos_dict, neg_dict\n",
    "\n",
    "pos_dict, neg_dict = find_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kate Hudson', 91.69873737373739),\n",
      " ('Lucy Liu', 43.47930839002267),\n",
      " ('Jennifer Lawrence', 39.818202260702265),\n",
      " ('Claire Danes', 39.555753968253974),\n",
      " ('Jessica Alba', 35.02333333333333),\n",
      " ('Anne Hathaway', 29.476388888888884),\n",
      " ('Jennifer Lopez', 24.532196969696955),\n",
      " ('Kerry Washington', 22.799531024531028),\n",
      " ('Kate', 21.302777777777777),\n",
      " ('Nicole Kidman', 19.533333333333335)]\n",
      "list length: 578\n"
     ]
    }
   ],
   "source": [
    "# find the best dressed\n",
    "print_top(pos_dict, 10)\n",
    "\n",
    "# pprint.pprint(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sienna Miller', -14.383333333333333),\n",
      " ('Kate', -12.599999999999993),\n",
      " ('Kate Hudson', -11.9125),\n",
      " ('Lucy Liu', -11.85708874458874),\n",
      " ('Alexander McQueen', -11.555555555555548),\n",
      " ('Jennifer Lawrence', -9.566666666666666),\n",
      " ('Halle Berry', -7.711111111111111),\n",
      " ('NN45RgjF', -5.688888888888887),\n",
      " ('Nicole Kidman', -5.466666666666667),\n",
      " ('Anne Hathaway', -5.196153846153847)]\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# find the worst dressed\n",
    "sorted_neg = sorted(neg_dict.items(), key=lambda e: e[1], reverse=False)\n",
    "pprint.pprint(sorted_neg[0:10])\n",
    "print(len(sorted_neg))\n",
    "# pprint.pprint(neg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_to_reduce(nominees):\n",
    "    names_clusters = []\n",
    "    names = list(nominees.keys())\n",
    "\n",
    "    for name in names:\n",
    "        # each name starts as a cluster\n",
    "        cluster = [name]\n",
    "        names_to_reduce = names[:]\n",
    "        names_to_reduce.remove(name)\n",
    "\n",
    "        # one vs. all comparisons\n",
    "        for i in names_to_reduce:\n",
    "            ratio = fuzz.ratio(name.lower(), i.lower())\n",
    "            # if similarity is larger than 75 or one name is contained in the other name\n",
    "            if ratio > 75 or re.search(name, i, flags=re.IGNORECASE) or re.search(i, name, flags=re.IGNORECASE):\n",
    "                cluster.append(i)\n",
    "\n",
    "        # if multiple names are identified in one cluster\n",
    "        if len(cluster) > 1:\n",
    "            names_clusters.append(cluster)\n",
    "\n",
    "    #     print(cluster)\n",
    "\n",
    "\n",
    "    # sort clusters\n",
    "    names_clusters.sort()\n",
    "    # sort within each cluster\n",
    "    names_clusters = ['|'.join(sorted(cluster)) for cluster in names_clusters]\n",
    "    # remove overlaps\n",
    "    names_clusters_reduced = [line.split('|') for line in list(set(names_clusters))]\n",
    "    # sort by length from shortest to longest (merge from the shortest)\n",
    "    names_clusters_reduced.sort(key=len)\n",
    "#     print('\\nnames clusters to merge:')\n",
    "#     pprint.pprint(names_clusters_reduced)\n",
    "#     print('\\n')\n",
    "    return names_clusters_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge names using cluster\n",
    "def reduce_names(nominees):\n",
    "    reduced_nominees = nominees.copy()\n",
    "    names_clusters_reduced = get_name_to_reduce(nominees)\n",
    "\n",
    "    def weighted_freq(element):\n",
    "        if element in reduced_nominees:\n",
    "            return abs(reduced_nominees[element]) * len(element)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    for cluster in names_clusters_reduced:\n",
    "        # select the longest entity name\n",
    "        selected_entity_name = max(cluster, key=weighted_freq)\n",
    "        cluster.remove(selected_entity_name)\n",
    "        # for names to be merged to the selected entity name\n",
    "        for name in cluster:\n",
    "            # if not deleted in previous cases, cumulate frequencies to the selected entity\n",
    "            if name in reduced_nominees and selected_entity_name in reduced_nominees:\n",
    "                reduced_nominees[selected_entity_name] += reduced_nominees[name]\n",
    "                del reduced_nominees[name]\n",
    "    return reduced_nominees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Helena Bonham Carter Golden Globes Dress', 446.9144635126779),\n",
      " ('Jennifer Lawrence', 167.4609639434639),\n",
      " ('Anne Hathaway', 64.91242063492064),\n",
      " ('Lucy Liu', 62.54736394557823),\n",
      " ('Bradley Cooper', 38.42079725829725),\n",
      " ('Nicole Kidman', 33.43333333333334),\n",
      " ('Amy Poehler', 31.587240259740256),\n",
      " ('Halle Berry', 13.763029100529101),\n",
      " ('Lea Michele', 12.798125),\n",
      " ('Emily Blunt', 12.052380952380954),\n",
      " ('Michelle Dockery', 10.905555555555555),\n",
      " ('Tina Fey', 10.181565656565656),\n",
      " ('Miu Miu', 10.166666666666664),\n",
      " ('Tom Ford', 10.035714285714285),\n",
      " ('Katherine McPhee', 8.158333333333333),\n",
      " ('Kevin Dior', 7.5),\n",
      " ('Marion Cotillard', 6.494444444444444),\n",
      " ('Bill Clinton', 6.297619047619047),\n",
      " ('Megan Fox', 3.675),\n",
      " ('Helen Mirren', 3.3249999999999997)]\n",
      "list length: 137\n"
     ]
    }
   ],
   "source": [
    "# merge similar names, find top 20\n",
    "reduced_pos = reduce_names(pos_dict)\n",
    "print_top(reduced_pos, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kate Hudson', -24.512499999999992),\n",
      " ('Lucy Liu', -17.05708874458874),\n",
      " ('Sienna Miller', -16.370833333333334),\n",
      " ('Alexander McQueen', -16.222222222222214),\n",
      " ('Jennifer Lawrence', -14.347619047619046),\n",
      " ('Halle Berry', -8.919444444444444),\n",
      " ('Anne Hathaway', -8.793881118881119),\n",
      " ('Eva Longoria', -8.641666666666666),\n",
      " ('NN45RgjF', -5.688888888888887),\n",
      " ('Nicole Kidman', -5.466666666666667),\n",
      " ('RT', -5.23670634920635),\n",
      " ('Lena Dunham', -4.641666666666667),\n",
      " ('Amy Poehler', -3.6802976190476184),\n",
      " ('PHOTOS', -3.1500000000000004),\n",
      " (\"Daniel Day Lewis'\", -2.9976190476190476),\n",
      " ('Jessica Chastain', -2.6025),\n",
      " ('Sorry', -2.4),\n",
      " ('Kristen Wiig', -2.386111111111111),\n",
      " ('Jodie Foster', -1.6714285714285713),\n",
      " ('Terrible Dress', -1.6666666666666667)]\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "# merge similar names, find top 20\n",
    "reduced_neg = reduce_names(neg_dict)\n",
    "sorted_neg = sorted(reduced_neg.items(), key=lambda e: e[1], reverse=False)\n",
    "pprint.pprint(sorted_neg[0:20])\n",
    "print(len(sorted_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amy Poehler': 18,\n",
      " 'Anne Hathaway': 8,\n",
      " 'Don Cheadle': 92,\n",
      " 'Halle Berry': 12,\n",
      " 'Helen Hunt': 82,\n",
      " 'Helen Mirren': 59,\n",
      " 'Jennifer Lawrence': 5,\n",
      " 'Lucy Liu': 4,\n",
      " 'Megan Fox': 43,\n",
      " 'Naeem Khan': 61,\n",
      " 'Nicole Kidman': 14,\n",
      " 'Quentin Tarantino': 116,\n",
      " 'Tina Fey': 64}\n"
     ]
    }
   ],
   "source": [
    "# find the most controversial \n",
    "def get_sorted_names(nominees, f):\n",
    "    sorted_nominees = sorted(nominees.items(), key=lambda e: e[1], reverse=f)\n",
    "    names = [pair[0] for pair in sorted_nominees]\n",
    "    return names\n",
    "\n",
    "pos_names = get_sorted_names(reduced_pos, True)\n",
    "neg_names = get_sorted_names(reduced_neg, False)\n",
    "\n",
    "contro_dict = {}\n",
    "for name in pos_names:\n",
    "    if name in neg_names:\n",
    "        contro_dict[name] = pos_names.index(name) + neg_names.index(name)\n",
    "\n",
    "pprint.pprint(contro_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python3",
   "language": "python",
   "name": "my_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
